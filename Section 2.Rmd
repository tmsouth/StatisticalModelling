---
title: "Section 2"
author: "Lily, James, Tobin"
date: "30/05/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(GGally)
source('conf_int_prop.R')
```

# Part B: Logistic Regression

## Introduction 
Breast cancer was the second most commonly diagnosed cancer in Australia in 2013 [^1]. The most effective method for breast cancer screening is Mammography. To confirm the diagnosis, invasive biopsies are performed. However, 70% of biopsies come back benign, indicating a high false positive rate in Mammography. To improve this process several computer-aided diagnosis (CAD) systems have been developed to help aid clinicians in making informed diagnoses.

The data in this examination contains 961 mammographic mass lesions with 445 of those lesions being malignant, given by the indicator variable Severity. Additionally for each of these lesions there are three attributes from the Breast Imaging Reporting and Data System (BI-RADS), including the lesion shape (round= 1, oval= 2, lobular= 3, irregular= 4), the margin (circumscribed= 1, microlobulated= 2, obscured= 3, ill-defined= 4, spiculated= 5) and the density (high= 1, iso= 2, low= 3, fat-containing= 4). 

This approach will attempt to develop a logistic predictive model for mammographic mass severity using the available predictor variables and to obtain predicted probabilities of mass severity that can used by clinicians to make informed diagnoses.


[^1]: Australian Institute of Health and Welfare, Cancer compendium: information and trends by cancer type, https://www.aihw.gov.au/reports/cancer/cancer-compendium-information-and-trends-by-cancer-type/report-contents/breast-cancer-in-australia,  [Accessed May 2018].

### Data cleaning


```{r}
mammo <- read.csv('mammo.txt', header = TRUE)
head(mammo)
```

After taking the data it is clear there are a few key issues to deal with in cleaning the data. The first is the incorrect classes of several of the variables and, as can be seen below, there are a number of data points that are missing certain attributes, these are currently set to "?". but should be set to "NA", for appropriate use within the models. These data points could be removed as they are missing some data, however this should not be done for two reasons. Firstly, incomplete data should not be thrown away as it may still contain valuable information. Furthermore, the final model may not include some of the predictor attributes, and some of the currently incomplete data may not be missing information in any of the include attributes. 

```{r}
table(mammo$Severity)
```
Severity has no missing data.
```{r}
table(mammo$Age) 
```
Age has 5 missing data points.
```{r}
table(mammo$Shape) 
```
Shape has 31 missing data points.

```{r}
table(mammo$Margin)
```
Margin has 48 missing data points.

```{r}
table(mammo$Density) 
```
Density has 76 missing data points.

```{r}
table(mammo$BI.RADS)
```
BI-RADS has 2 missing data points, but this class will not be used in our model, and is not of high importance.


This data is now cleaned by setting "?"'s to NA's and fixing the attribute classes.
```{r}
class(mammo$Age)
mammo$Age[mammo$Age == "?"] <- NA
mammo$Age <- as.numeric(mammo$Age)
summary(mammo$Age, exclude = FALSE) 
```
Age has its 5 missing data points set to NA and the variable is set to numeric. 
```{r}
class(mammo$Shape)
mammo$Shape <- as.character(mammo$Shape)
mammo$Shape[mammo$Shape == "?"] <- NA
mammo$Shape <- factor(mammo$Shape)
summary(mammo$Shape, exclude = FALSE) 
```
Shape has its 31 missing data points set to NA and the variable is set to a factor 

```{r}
class(mammo$Margin)
mammo$Margin <- as.character(mammo$Margin)
mammo$Margin[mammo$Margin == "?"] <- NA
mammo$Margin <- factor(mammo$Margin)
summary(mammo$Margin, exclude = FALSE) 
```
Margin has its 48 missing data points set to NA and the variable is set to a factor 

```{r}
class(mammo$Density)
mammo$Density <- as.character(mammo$Density)
mammo$Density[mammo$Density == "?"] <- NA
mammo$Density <- factor(mammo$Density)
summary(mammo$Density, exclude = FALSE) 
```
Density has its 76 missing data points set to NA and the variable is set to a factor 

```{r}
class(mammo$Severity)
mammo$Severity <- as.numeric(mammo$Severity)
summary(mammo$Severity, exclude = FALSE)
```
Severity is set to a integer.


Finally, BI-RADS has it's 2 missing data points set to NA. Additionally, the data has a clear outlier in it that is set to NA as well. Again, this is not overly important as BI-RADS will not be used as a predictor in this model.
```{r}
class(mammo$BI.RADS)
mammo$BI.RADS <- as.character(mammo$BI.RADS)
mammo$BI.RADS[mammo$BI.RADS == "?"] <- NA
mammo$BI.RADS <- factor(mammo$BI.RADS)
summary(mammo$BI.RADS, exclude = FALSE) # 2 NAs, 1 outlier
mammo$BI.RADS[mammo$BI.RADS == 55] <- NA # Set outlier to NA
mammo$BI.RADS <- as.numeric(mammo$BI.RADS) 
summary(mammo$BI.RADS, exclude = FALSE) # 3 NAs
```

# Can these varibles be interpolated (no)

## Data Visualisation
To examine the relationship between each of the individual variables, a plot of the relationships between the variable is made. 
```{r, warning=FALSE}
mammo %>%
  mutate(Severity = as.factor(Severity)) %>%
  select(2:6) %>%
  ggpairs(upper = list(continuous = "blank",
                       combo ="blank",
                       discrete = "blank",
                       na = "blank"),
          lower = list(continuous = "cor",
                       combo = "box_no_facet",
                       discrete = "facetbar",
                       na = "na")) 
```

Age is mostly normally distributed around a mean of 39.48. Shape and Margin have a slight linear increase with age but Density does not. Severity appears to have a correlation between being malignant and a higher age.

Shape has a large portion in the lobular category, this category also has a high proportion of malignancy.

Margin has a strong correlation between the first category, circumscribed, and being benign.The second category has very little data and may not be of much value to the model.

Density has a overwhelming popularity of the third class of "low". This makes it difficult to mind any significant findings with respect to how the classes effect the Severity.

Finally Severity has a mostly balanced proportion of benign to malignant which is ideal for fitting an accurate model.

### Confidence intervals

We made confidecne intervals because we could. We did this because it gave us another look into which variables were affecting our response variable. T

``` {r}
summary(mammo$Age)

hist(mammo$Age)
mammo$ageGroup <- cut(mammo$Age,
                        breaks = c(0,20,40,60,80),
                        labels = c("20 and Under","21-40","41-60","Over 60"))

confidenceInt <- mammo %>% 
  split(.$ageGroup) %>%
  map_df(~conf_int_prop(.$Severity), .id = "AgeGroup")

ggplot(confidenceInt, aes(x = AgeGroup, y = Proportion)) +
  geom_point(size = 4) +
  geom_errorbar(aes(ymax = Upper, ymin = Lower)) +
  labs(y = "Proportion of Malignant Cases") +
  ggtitle("Confidence Intervals for the Proportion of Malignant Cases per Age Group")

# We are 95% confident the true proportion of people 20 and under with a malignant mass lies between 3% and 14%

# Shape

mammo$Shape.orig <- mammo$Shape

confidenceInt <- mammo %>% 
  split(.$Shape.orig) %>%
  map_df(~conf_int_prop(.$Severity), .id = "Shape")

ggplot(confidenceInt, aes(x = Shape, y = Proportion)) +
  geom_point(size = 4) +
  geom_errorbar(aes(ymax = Upper, ymin = Lower))

levels(mammo$Shape)[levels(mammo$Shape)=="1"] <- "1 and 2"
levels(mammo$Shape)[levels(mammo$Shape)=="2"] <- "1 and 2"
table(mammo$Shape)

confidenceInt <- mammo %>% 
  split(.$Shape) %>%
  map_df(~conf_int_prop(.$Severity), .id = "Shape")

ggplot(confidenceInt, aes(x = Shape, y = Proportion)) +
  geom_point(size = 4) +
  geom_errorbar(aes(ymax = Upper, ymin = Lower))

# Margin

confidenceInt <- mammo %>% 
  split(.$Margin) %>%
  map_df(~conf_int_prop(.$Severity), .id = "Margin")

ggplot(confidenceInt, aes(x = Margin, y = Proportion)) +
  geom_point(size = 4) +
  geom_errorbar(aes(ymax = Upper, ymin = Lower))

# Density

confidenceInt <- mammo %>% 
  split(.$Density) %>%
  map_df(~conf_int_prop(.$Severity), .id = "Density")

ggplot(confidenceInt, aes(x = Density, y = Proportion)) +
  geom_point(size = 4) +
  geom_errorbar(aes(ymax = Upper, ymin = Lower))
```

## Making a Model

### Using the right data
Firstly, we are only able to fit a model to entries in the data frame that are complete. To do this, we created a logical vector for all the data that references which data entries have information for all variables.

``` {r complete}
complete=!is.na(mammo$Age)&!is.na(mammo$Shape)&!is.na(mammo$Margin)&!is.na(mammo$Density) # Use complete data for models
```

### The Full Model

As we begin the model creation process, our first step is to create a model that uses all of our predictor variables to model our response variable, severity. Of the 4 predictor variables, only age is a numerical variable. Shape, Margin, and Density are all categorical variables which contain levels. In r, when fitting a model to categorical variables, the model uses a reference category. The reference category for Shape should clearly be the combined 1 and 2 level, as each level seems to show a distinct difference in the proportion of malignant masses, and this combined level contains the greatest number of data entries. However for margin, choosing a reference category because more difficult. The default reference level 1 is not the best selection. As we saw from the confidence intervals, category 1 has a relatively low proportion malignant mass cases, while the other categories 2,3,4, and 5 do not deviate from one another all that much. With 1 as the reference level, all the other levels appear significantly different, when really it is 1 that is the oddball. Hence we must decide on another reference level. Category 4 has the largest number of data points, and the true proportion of malignant cases with a margin of 4 has a narrow range of possibilities relative to the other categories, meaning any other facets of the data will be more prevalent when fitting the model, therefore this is the reference point we will use.

``` {r full}
mammo$Margin <- relevel(mammo$Margin, ref="1")

mod.full1 <- glm(formula = Severity ~ Age + Shape + Margin + Density,
               family = binomial,
               data = mammo[complete,])

table(mammo$Margin)

mammo$Margin <- relevel(mammo$Margin, ref="4")

mod.full4 <- glm(formula = Severity ~ Age + Shape + Margin + Density,
                 family = binomial,
                 data = mammo[complete,])


summary(mod.full1)
summary(mod.full4)

mod.full <- mod.full4
```

### Model by stepwise selection

Pretty self explanatory, r fits the model based on AIC values.

``` {r stepwise}
mod.step <- step(mod.full, direction = "both", trace = 0)
summary(mod.step)
```

Here, we will be creating a model by removing the least significant variable. The first iteration this was easy as none fo the coefficients for density were significant. We then also removed Margin, as only 2 of the 4 coefficients were statistically significant.

```{r}
mod.back <- mod.full

summary(mod.back)
mod.back <- update(mod.back, .~. - Density)
summary(mod.back)
mod.back <- update(mod.back, .~. - Margin)
summary(mod.back)
```

## Choosing models

We now hve 3 model created, but which to choose? Each smaller model only required the removal of one variable.  First, we wanted to ensure that removing this variable actually had a significant impact on the model. To do this, we essentially checked if we could set the coefficients for that variable equal to 0. this could be found by comparing the difference in residual deviances to the q value (i cant describe this things (qchisq(1-0.05, df = 3))

```{r compare}
summary(mod.full)
summary(mod.back)
summary(mod.step)
qchisq(1-0.05, df = 3)
mod.back$deviance - mod.full$deviance 
anova(mod.back, mod.full) # reject hypothesis that all coefficients are equal

qchisq(1-0.05, df = 2)
mod.step$deviance - mod.back$deviance
anova(mod.step, mod.back) # These literally say the same thing but in the prac we use the difference

AIC(mod.full, mod.step, mod.back)
```


### Prediction to verify model

Another way of assessing the goodness of fit of a model it to see how well predicts values. This works especially well for predicting binary outcomes as you can calculate a simple proportion of correct predictions. Firstly we predicted values for the data that was used to fit the model. This gives us an about 79.6% success rate.

```{r}
predict <- predict(mod.step, newdata = mammo ,type="response")
predict.df <- data.frame(predict.prob = predict)

predict.df.indexed <- data.frame(predict.df, id = row.names(predict.df))
mammo.indexed <- data.frame(mammo, id = row.names(mammo))

mammo.predict <- left_join(mammo.indexed, predict.df.indexed, by="id")
mammo.predict <- mammo.predict[ , !names(mammo.predict) %in% c("id")]


#Calculate the percentage that our model correctly predicts Severity
mammo.predict %>%
  mutate(predict = (predict.prob >= 0.5),
         predict = as.integer(predict),
         correct = (predict == Severity)) %>%
  count(correct) %>%
  summarise(hit.rate = n[2]/(n[1] + n[2])) %>%
  first() %>%
  round(3)
```

The second approach is to fit the model to only half of the data we have available and then attempt to predict the values of the other half of the data. Doing this we get a success rate of about 78.7% which is barely less than above. This is evidence to justify our model as valid and useful for prediction. 


```{r}
train <- slice(mammo[complete,], 1:400)
test <- slice(mammo[complete,], 401:831)

mod.train <- glm(Severity ~ Age + Shape, data = train, family = "binomial")

predict <- predict(mod.train, newdata = test ,type="response")
predict.df <- data.frame(predict.prob = predict)

predict.df.indexed <- data.frame(predict.df, id = row.names(predict.df))
mammo.indexed <- data.frame(test, id = row.names(test))

mammo.predict <- left_join(mammo.indexed, predict.df.indexed, by="id")
mammo.predict <- mammo.predict[ , !names(mammo.predict) %in% c("id")]


#Calculate the percentage that our model correctly predicts Severity
mammo.predict %>%
  mutate(predict = (predict.prob >= 0.5),
         predict = as.integer(predict),
         correct = (predict == Severity)) %>%
  count(correct) %>%
  summarise(hit.rate = n[2]/(n[1] + n[2])) %>%
  first() %>%
  round(3)
```



Prediction can also be used to inform clinical decisions. To that end we produced a table that gives predictive probabilities for different ages and shapes.

```{r}
pred1 <- predict(mod.step, newdata = data.frame(Age=seq(from=10, to=80, by=10), Shape = "1 and 2"), type = "response")
pred3 <- predict(mod.step, newdata = data.frame(Age=seq(from=10, to=80, by=10), Shape = "3"), type = "response")
pred4 <- predict(mod.step, newdata = data.frame(Age=seq(from=10, to=80, by=10), Shape = "4"), type = "response")

pred <- cbind(pred1, pred3, pred4)
}{- b0vf}

diag.table <- data.frame(round(pred, 2), row.names = seq(from=10, to=80, by=10))
colnames(diag.table) <- c("Round or Oval", "Lobular", "Irregular")
diag.table
```


Above each row represents a different age and each column a different shape.